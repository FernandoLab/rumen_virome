---
title: "Viral Groups"
output:
  html_document:
    keep_md: true
---

Define vial groups based on contig similarity done via blast pairwise comparisons. Same approach as outlined in http://www.nature.com/ismej/journal/v9/n10/full/ismej201528a.html. First, need to get the abundance of deep viral and viral contigs.

```{r, engine="bash"}
cat vmg.contigs.filter.fasta vmg.illumina.contigs.filter.fasta > vmg.ion_illumina.contigs.filter.fasta

mkdir vmg_ion_illumina_contigs_bowtie
bowtie2-build vmg.ion_illumina.contigs.filter.fasta vmg_ion_illumina_contigs_bowtie/vmg_ion_illumina_contigs_bowtie_db

for f in viral_qc/*finalQC.fastq
do
  filename=$(basename "$f")
  filename="${filename%_*}"
  bowtie2 -U $f --end-to-end --sensitive -p 10 -x vmg_ion_illumina_contigs_bowtie/vmg_ion_illumina_contigs_bowtie_db -S vmg_ion_illumina_contigs_bowtie/$filename.sam --un vmg_ion_illumina_contigs_bowtie/$filename.unaligned.txt --al vmg_ion_illumina_contigs_bowtie/$filename.aligned.txt
done

for f in deep_viral_qc/*illumina_finalQC.fastq
do
  filename=$(basename "$f")
  filename="${filename%_*}"
  bowtie2 -U $f --end-to-end --sensitive -p 10 -x vmg_ion_illumina_contigs_bowtie/vmg_ion_illumina_contigs_bowtie_db -S vmg_ion_illumina_contigs_bowtie/$filename.sam --un vmg_ion_illumina_contigs_bowtie/$filename.unaligned.txt --al vmg_ion_illumina_contigs_bowtie/$filename.aligned.txt
done
```

Blast the contigs in all vs all blastn search and filter with script used in ISME paper above to define groups.

```{r, engine="bash"}

makeblastdb -in vmg.ion_illumina.contigs.filter.fasta -dbtype nucl -parse_seqids

blastn -db vmg.ion_illumina.contigs.filter.fasta -query vmg.ion_illumina.contigs.filter.fasta -out vmg.ion_illumina.contigs.filter.blastn.txt -evalue 0.0001 -outfmt 0 -num_alignments 10000 -num_descriptions 10000

python scripts/BLAST2Network.py --input_fn vmg.ion_illumina.contigs.filter.blastn.txt --output_fn blast2network.txt --evalue 1e-10 --num_inputs 470106 --membership_per_community --data_represented --contig_community_cutoff 5

# will fail, have to call again to continue analysis
python scripts/BLAST2Network.py --input_fn vmg.ion_illumina.contigs.filter.blastn.txt --output_fn blast2network.txt --evalue 1e-10 --num_inputs 470106 --membership_per_community --data_represented --contig_community_cutoff 5

# blast2network.txt-Partition-Contig-Sizes.tab tells number of contigs per group
# blast2network.txt-Partition-Membership.tab tells the group ID of each contig

# get the abundances of each contig from SAM files
for f in vmg_ion_illumina_contigs_bowtie/*.sam
do
  filename=$(echo $f | cut -d. -f1)
  samtools view -bS $f > $filename.bam
  samtools sort $filename.bam -o $filename.sorted.bam
  samtools index $filename.sorted.bam
  filename2=$(echo $filename | cut -d/ -f2)
  echo 'OTU'$'\t'$filename2 > $filename.contig_raw_abundance.txt
  samtools idxstats $filename.sorted.bam | cut -f 1,3 | awk ' $2 > 0 ' >> $filename.contig_raw_abundance.txt
done

cat vmg_ion_illumina_contigs_bowtie/*contig_raw_abundance.txt > vmg_ion_illumina_contigs_bowtie/vmg_ion_illumina_contig_raw_abundance.txt
```

Calculate some summary stats of the viral groups and filter out those groups with less than 5 contigs and representing less than 10,000 reads.

```{r}
library(dplyr)
options(stringsAsFactors=FALSE)

contig_table <- read.table('vmg_ion_illumina_contigs_bowtie/vmg_ion_illumina_contig_raw_abundance.txt', header=FALSE, comment.char="", sep="\t")
contig_table_sub <- subset(contig_table, V1 != "OTU")
colnames(contig_table_sub) <- c("contig", "ab")
contig_table_sub$ab <- as.numeric(contig_table_sub$ab)
contig_table_group <- contig_table_sub %>%
	group_by(contig) %>%
	summarise(ab = sum(ab))

contig_mem <- read.table("blast2network.txt-Partition-Membership.tab", sep="\t", header=FALSE)
colnames(contig_mem) <- c("contig", "mem")
dim(contig_mem) #233430

contig_mem_ab <- merge(contig_mem, contig_table_group, by="contig")

dim(contig_mem_ab) #233151; lose some contigs b/c no reads aligned to them

mem_ab <- contig_mem_ab %>%
	group_by(mem) %>%
	summarise(ab = sum(ab), freq=n())	

dim(mem_ab) #31233; lose groups due to loss of contigs

mem5_ab10000 <- contig_mem_ab %>%
	group_by(mem) %>%
	summarise(ab = sum(ab), freq=n()) %>%
	filter(freq >= 5) %>%
	filter(ab >= 10000)	 

dim(mem5_ab10000) #406
sum(mem5_ab10000$ab) #38059853
sum(contig_table_sub$ab) #47624294
sum(mem5_ab10000$ab) / sum(contig_table_sub$ab) #0.7991689

write.table(mem5_ab10000, file="blast2network.txt-Partition-Contig-Sizes-filter.tab", col.names=TRUE, row.names=FALSE, quote=FALSE, sep="\t")
```

Get the abundance of viral groups across samples and subsequently identify which of the groups are "core". See manuscript for discussion regarding core viral groups.

```{r, engine="bash"}
python scripts/get_viral_group_abundance.py

for f in vmg_ion_illumina_contigs_bowtie/*group_raw_abundance.txt
do
  filename=$(basename "$f")
	filename="${filename%.txt}"
	biom convert --table-type="OTU table" --to-json -i $f -o vmg_ion_illumina_contigs_bowtie/$filename.biom
done

merge_otu_tables.py -i vmg_ion_illumina_contigs_bowtie/V1.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V2.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V3.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V4.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V5.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V6.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V7.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V8.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V9.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V10.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V11.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V12.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V13.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V14.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V15.group_raw_abundance.biom -o vmg_ion_illumina_contigs_bowtie/vmg.group_raw_abundance.biom

merge_otu_tables.py -i vmg_ion_illumina_contigs_bowtie/V4_illumina.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V9_illumina.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V10_illumina.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V11_illumina.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V12_illumina.group_raw_abundance.biom,vmg_ion_illumina_contigs_bowtie/V13_illumina.group_raw_abundance.biom -o vmg_ion_illumina_contigs_bowtie/vmg_illumina.group_raw_abundance.biom

biom convert --table-type="OTU table" --to-tsv -i vmg_ion_illumina_contigs_bowtie/vmg.group_raw_abundance.biom -o vmg_ion_illumina_contigs_bowtie/vmg.group_raw_abundance.txt

biom convert --table-type="OTU table" --to-tsv -i vmg_ion_illumina_contigs_bowtie/vmg_illumina.group_raw_abundance.biom -o vmg_ion_illumina_contigs_bowtie/vmg_illumina.group_raw_abundance.txt
```

```{r}
group_ab <- read.table('vmg_ion_illumina_contigs_bowtie/vmg.group_raw_abundance.txt', header=TRUE, skip=1, comment.char="", row.names=1, sep="\t")
core_group_ab <- group_ab[apply(group_ab[,-1], 1, function(x) all(x>10)),]
dim(core_group_ab) #38 groups found in all samples
sum(colSums(core_group_ab)) #3,258,184; reads in core groups in ion dataset
sum(colSums(core_group_ab)) / sum(contig_table_sub$ab) #0.06841433

write.table(core_group_ab, file='core_viral_groups.txt', row.names=TRUE, col.names=NA, sep="\t")
```

Cluster viral groups with RefSeq Genomes to see how novel the rumen viral groups are compared to currently known viruses.

```{r, engine="bash"}
wget ftp://ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.1.1.genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/refseq/release/viral/viral.2.1.genomic.fna.gz

gunzip -d viral.1.1.genomic.fna.gz
gunzip -d viral.2.1.genomic.fna.gz

cat viral.1.1.genomic.fna viral.2.1.genomic.fna > viral_refseq.fna

cat vmg.ion_illumina.contigs.filter.fasta viral_refseq.fna > vmg.ion_illumina.contigs.filter.cat_refseq.fasta

makeblastdb -in vmg.ion_illumina.contigs.filter.cat_refseq.fasta -dbtype nucl -parse_seqids

blastn -db vmg.ion_illumina.contigs.filter.cat_refseq.fasta -query vmg.ion_illumina.contigs.filter.cat_refseq.fasta -out vmg.ion_illumina.contigs.filter.cat_refseq.blastn.txt -evalue 0.0001 -outfmt 0 -num_alignments 10000 -num_descriptions 10000

python scripts/BLAST2Network.py --input_fn vmg.ion_illumina.contigs.filter.cat_refseq.blastn.txt --output_fn blast2network_refseq.txt --evalue 1e-10 --num_inputs 477551 --membership_per_community --data_represented --contig_community_cutoff 5

# will fail, call again to jump start analysis
python scripts/BLAST2Network.py --input_fn vmg.ion_illumina.contigs.filter.cat_refseq.blastn.txt --output_fn blast2network_refseq.txt --evalue 1e-10 --num_inputs 477551 --membership_per_community --data_represented --contig_community_cutoff 5

python find_group_refviral.py 
#20 groups
```

Plot the abundance of viral groups across samples.

```{r}
library(metagenomeSeq)
library(edgeR)
library(gridExtra)
library(ggplot2)
library(ggthemes)
library(gplots)
library(grid)
library(vegan)

group_ab <- read.table("vmg_ion_illumina_contigs_bowtie/vmg.group_raw_abundance.txt", sep="\t", header=TRUE, comment.char="", row.names=1, skip=1)
group_ab_mat <- as.matrix(group_ab)

map <- read.table("viral_mapping.txt", sep="\t", header=TRUE, comment.char="", row.names=1)
map$reads <- as.numeric(as.character(map$reads))
map <- map[match(colnames(group_ab), row.names(map)),]

d <- DGEList(counts=group_ab_mat, lib.size=map$reads)
#log_cpm <- cpm(d,log=TRUE, normalized.lib.sizes=TRUE)
cpm <- cpm(d,log=FALSE, normalized.lib.sizes=TRUE)
#cpm_scale <- cpm * 1000


phenotypeData <- AnnotatedDataFrame(map)
vgroups <- newMRexperiment(cpm,phenoData=phenotypeData,libSize=map$reads)

map$few_cols <- c("#FAA75B", "#FAA75B", "#7AC36A", "#F15A60", "#5A9BD4", "#7AC36A", "#7AC36A", "#FAA75B", "#5A9BD4", "#F15A60", "#5A9BD4", "#5A9BD4", "#F15A60", "#FAA75B", "#7AC36A")
map$few_cols <- as.character(map$few_cols)

#make plot, test, with legend wanted then paste it to the heatmap
map$TDN <- as.numeric(as.character(map$TDN))
test <- ggplot(map, aes(TDN, reads, color=Diet, group=Diet)) + 
  geom_point(size=2, shape=15) +
  scale_color_few(palette="medium") +
  theme(legend.text=element_text(size=10), legend.key = element_blank(), legend.title = element_blank(), legend.key.height = unit(0.35, "cm"), legend.key.width = unit(0.01, "cm"), legend.background = element_rect(fill=alpha('white', 0.0)))

g <- ggplot_gtable(ggplot_build(test))$grobs
g[[8]]$vp$x <- unit(-0.025, 'npc')
g[[8]]$vp$y <- unit(0.735, 'npc')

#pairs.breaks <- seq(-2, 19, by=0.5)
heatmapCols <- colorRampPalette(c("white", "yellow2", "orange", "red"), space = "rgb")(50)
log_label = c(as.expression("\n"~"Log"[2]~"Counts"~"Per"~"Million"))

tiff("viral_group_hm.tiff", res=600, compression = "lzw", width=6, height=6, units="in") 
plotMRheatmap(obj = vgroups, norm=FALSE, log=TRUE, n = 406, trace = "none", col = heatmapCols, ColSideColors = map$few_cols, labRow=NA, srtCol=0, key=FALSE, key.title=NA, labCol=NA, key.xlab=log_label, key.ylab="", margins=c(1,1), distfun = function(x) vegdist(x, method = "bray"), hclustfun = function(x) hclust(x, method = "ward.D2"), keysize=1.635)
grid::pushViewport(plotViewport())
grid::grid.draw(g[[8]])
dev.off()
```